{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Prepare data -> get staypoints and daily vehicle count\n",
    "- consecutive trips ( represented by **tripcount** in input csv) within a day are assigned same trip_code ( else different trip_code)\n",
    "- trip_code is used for merging trips i.e. merge consecutive trips with same trip_code as a single output row \n",
    "- remove entries with stay_time < threshold_in_sec ( e.g. 1800 seconds i.e. 30 minutes)\n",
    "- Sample Input:\n",
    "    -  ./new_data/gpsdata_202001-03.csv\n",
    "- Sample Output:\n",
    "    - ./new_data/output/gpsdata_202001-03_staypoints.csv\n",
    "    - ./new_data/output/gpsdata_202001-03_dailyvehicle.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "#trip_code: consecutive trips within a day is assigned same trip_code ( else different trip code)\n",
    "# It is used for merging trips i.e. merge consecutive tripcount as a single output row \n",
    "def assign_trip_code(df_single_ap):\n",
    "    df_single_ap['trip_code']=None\n",
    "    df_single_ap = df_single_ap.reset_index(drop=True)\n",
    "    date_old = 0\n",
    "    trip_count_old = 0\n",
    "    trip_code = 0\n",
    "    \n",
    "    for idx,row in df_single_ap.iterrows():\n",
    "        #print(idx)\n",
    "        cur_trip_count = df_single_ap.iloc[idx].trip_prevs\n",
    "        cur_date = df_single_ap.iloc[idx].date\n",
    "        #print(cur_trip_count, trip_count_old, trip_code)\n",
    "        \n",
    "        if (trip_count_old ) == cur_trip_count:\n",
    "            df_single_ap.at[idx,'trip_code'] = str(trip_code)\n",
    "        elif ( ( (trip_count_old +1 ) == cur_trip_count) ):\n",
    "            if date_old == cur_date:\n",
    "                df_single_ap.at[idx,'trip_code'] =  str(trip_code)            \n",
    "            else:\n",
    "                trip_code += 1\n",
    "        else:\n",
    "            trip_code += 1\n",
    "            df_single_ap.at[idx,'trip_code'] =  str(trip_code)\n",
    "\n",
    "        trip_count_old = cur_trip_count\n",
    "        date_old = cur_date\n",
    "\n",
    "    return df_single_ap \n",
    "\n",
    "def read_input_data(csv_file):\n",
    "    df = pd.read_csv(csv_file,usecols=['serial','tripid','tripcount','tlm_datagettime','lat','lon'])\n",
    "    #df = pd.read_csv(csv_file)#,usecols=['serial','tripid','tripcount','tlm_datagettime','lat','lon'])\n",
    "\n",
    "    df.rename(columns = {'serial':'ap_id','tlm_datagettime':'timestamp'}, inplace = True)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df=df.sort_values(by=['timestamp'])\n",
    "    df['date'] = pd.to_datetime(df['timestamp']).dt.date\n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_trip_summary(df):# summarize each trip\n",
    "    \n",
    "    arr_ap_ids = df.ap_id.unique()\n",
    "\n",
    "    arr_trip_summary = []\n",
    "    for ap_id in arr_ap_ids:\n",
    "        \n",
    "        df_single_ap = df.query(\"ap_id=='\"+ap_id+\"'\").copy()\n",
    "        df_single_ap = df_single_ap.sort_values(by=['timestamp'])\n",
    "        arr_trips = df_single_ap.tripcount.unique()\n",
    "        '''\n",
    "        if ap_id=='AP520040':\n",
    "            #display(df_single_ap)\n",
    "            print (arr_trips)\n",
    "        '''\n",
    "        #trip_count = arr_trips[0]\n",
    "        #trip_count\n",
    "        ts_prevs = df_single_ap.timestamp.min()\n",
    "        lat_prevs = df_single_ap.iloc[0].lat\n",
    "        lon_prevs = df_single_ap.iloc[0].lon\n",
    "\n",
    "        trip_count_prevs = -9 #  small number (far below real trip_count value) for initialization purpose\n",
    "        for trip_count in arr_trips:\n",
    "\n",
    "            # process consicutive trips only e.g. trip_count_prevs = 12 and  trip_count=13\n",
    "            df_single_trip = df_single_ap.query(\"tripcount=='\"+str(trip_count)+\"'\").copy()\n",
    "            df_single_trip = df_single_trip.sort_values(by=['timestamp'])\n",
    "            max_ts = df_single_trip.timestamp.max()\n",
    "            min_ts= df_single_trip.timestamp.min()\n",
    "\n",
    "            stay_time =  min_ts - ts_prevs\n",
    "            trip_time = (max_ts - min_ts).total_seconds()\n",
    "\n",
    "            lat_min = df_single_trip.iloc[0].lat\n",
    "            lon_min = df_single_trip.iloc[0].lon\n",
    "            lat_max = df_single_trip.iloc[len(df_single_trip)-1].lat \n",
    "            lon_max = df_single_trip.iloc[len(df_single_trip)-1].lon\n",
    "\n",
    "            avg_lat = (lat_prevs + lat_min)/2\n",
    "            avg_lon = (lon_prevs + lon_min)/2\n",
    "\n",
    "            lat_prevs = lat_max\n",
    "            lon_prevs = lon_max\n",
    "\n",
    "            if ( trip_count_prevs  == trip_count-1):\n",
    "                \n",
    "                '''\n",
    "                if ap_id=='AP520040':\n",
    "                    print (trip_count_prevs, trip_count,' -- ', min_ts.date(), ts_prevs.date())\n",
    "                '''         \n",
    "                if min_ts.date() != ts_prevs.date():\n",
    "                    trip_count_prevs = trip_count\n",
    "                    ts_prevs = max_ts\n",
    "                    #print ('SKIP: ', min_ts,ts_prevs)                    \n",
    "                    continue\n",
    "                    \n",
    "                #if ap_id=='AP520040':\n",
    "                    #print ( '\\t' ,trip_count_prevs, trip_count,' -- ', min_ts.date(), ts_prevs.date())\n",
    "                    \n",
    "                arr_trip_summary.append({\n",
    "                    'ap_id': ap_id,\n",
    "\n",
    "                    'trip_prevs': trip_count_prevs,\n",
    "                    'trip_count': trip_count,\n",
    "                    'ts_prevs': ts_prevs,\n",
    "                    'ts_min': min_ts,\n",
    "                    'stay_time': stay_time.total_seconds(),\n",
    "                    'avg_lon_with_prvs': avg_lon,\n",
    "                    'avg_lat_with_prvs': avg_lat,\n",
    "              \n",
    "                    })\n",
    "\n",
    "            trip_count_prevs = trip_count\n",
    "            ts_prevs = max_ts\n",
    "\n",
    "    trip_df =  pd.DataFrame(arr_trip_summary)      \n",
    "    trip_df['date'] = trip_df['ts_min'].dt.date\n",
    "\n",
    "    return trip_df\n",
    "\n",
    "\n",
    "# if multiple consecutive trips in a single day then merge them as single one\n",
    "def merge_consecutive_trips_in_single_day(trip_df, threshold_in_sec, final_csv):\n",
    "    \n",
    "    arr_ap_ids = trip_df.ap_id.unique()\n",
    "    arr_trip_merged = []\n",
    "    for ap_id in arr_ap_ids:\n",
    "        df_single_ap = trip_df.query(\"ap_id=='\"+ap_id+\"'\").copy()\n",
    "        \n",
    "        df_single_ap = assign_trip_code(df_single_ap)\n",
    "        #display(df_single_ap)\n",
    "\n",
    "        arr_trip_code = df_single_ap.trip_code.unique()\n",
    "\n",
    "        for trip_code in arr_trip_code:\n",
    "            df_trip_code = df_single_ap.query(\"trip_code=='\"+str(trip_code)+\"'\")\n",
    "\n",
    "            arr_trip_merged.append( {\n",
    "                        'ap_id': ap_id,\n",
    "                        'date':df_trip_code.date.min(),\n",
    "                        'trip_prevs': df_trip_code.trip_prevs.min(),\n",
    "                        'trip_count': df_trip_code.trip_count.max(),\n",
    "                        'ts_prevs_stop': df_trip_code.ts_prevs.min(),\n",
    "                        'timestamp': df_trip_code.ts_min.max(), # timnestamp of car starting \n",
    "                        'stay_time': df_trip_code.stay_time.sum(),\n",
    "                        'lon': df_trip_code.avg_lon_with_prvs.mean(), # avg_lon_with_prvs\n",
    "                        'lat':  df_trip_code.avg_lat_with_prvs.mean(), # avg_lat_with_prvs\n",
    "                        'trip_code': trip_code\n",
    "                        } )\n",
    "\n",
    "    df_final =  pd.DataFrame(arr_trip_merged) \n",
    "    \n",
    "    # remove entries with stay_time < threshold_in_sec ( e.g. 1800 seconds)\n",
    "    df_final = df_final[df_final['stay_time']>=threshold_in_sec]\n",
    "    df_final.to_csv(final_csv, index=False) \n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_in_sec = 1800 # # remove entries with stay_time < 1800 seconds\n",
    "#input_csv='data/2019-04_2019-08_GyokuSendo.csv'\n",
    "#final_csv='data/2019-04_2019-08_GyokuSendo_staypoints_2.csv'\n",
    "'''\n",
    "input_csv='new_data/gpsdata_202001-03.csv'\n",
    "final_csv='new_data/output/gpsdata_202001-03_staypoints.csv'\n",
    "daily_vehicle_csv='new_data/output/gpsdata_202001-03_dailyvehicle.csv'\n",
    "'''\n",
    "input_csv= 'new_data/gpsdata_201803-12.csv'\n",
    "final_csv=  'new_data/output/gpsdata_201803-12_staypoints.csv'\n",
    "daily_vehicle_csv='new_data/output/gpsdata_201803-12_dailyvehicle.csv'\n",
    "\n",
    "\n",
    "df = read_input_data( input_csv )\n",
    "trip_df = prepare_trip_summary(df)\n",
    "df_final = merge_consecutive_trips_in_single_day(trip_df, threshold_in_sec, final_csv)\n",
    "#print(len(trip_df), len(df_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.query(\"ap_id=='AP622732'\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count and save daily unique vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily_unique_ap = df_final[['date','ap_id']]\n",
    "df_daily_unique_ap = df_daily_unique_ap.drop_duplicates(['date','ap_id'])\n",
    "df_daily=df_daily_unique_ap[['date','ap_id']].groupby('date').agg(['count']).reset_index()\n",
    "df_daily.to_csv(daily_vehicle_csv ,  index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine result and inoutdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ap_id</th>\n",
       "      <th>date</th>\n",
       "      <th>trip_prevs</th>\n",
       "      <th>trip_count</th>\n",
       "      <th>ts_prevs_stop</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>stay_time</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>trip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6369</th>\n",
       "      <td>AP622732</td>\n",
       "      <td>2018-04-15</td>\n",
       "      <td>602</td>\n",
       "      <td>605</td>\n",
       "      <td>2018-04-15 16:02:14</td>\n",
       "      <td>2018-04-15 17:39:21</td>\n",
       "      <td>5825.0</td>\n",
       "      <td>127.748504</td>\n",
       "      <td>26.141682</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370</th>\n",
       "      <td>AP622732</td>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>615</td>\n",
       "      <td>616</td>\n",
       "      <td>2018-04-16 15:34:11</td>\n",
       "      <td>2018-04-16 16:59:10</td>\n",
       "      <td>5099.0</td>\n",
       "      <td>127.747982</td>\n",
       "      <td>26.141301</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6371</th>\n",
       "      <td>AP622732</td>\n",
       "      <td>2018-05-20</td>\n",
       "      <td>877</td>\n",
       "      <td>878</td>\n",
       "      <td>2018-05-20 14:01:13</td>\n",
       "      <td>2018-05-20 16:42:19</td>\n",
       "      <td>9666.0</td>\n",
       "      <td>127.747158</td>\n",
       "      <td>26.140155</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6372</th>\n",
       "      <td>AP622732</td>\n",
       "      <td>2018-05-28</td>\n",
       "      <td>954</td>\n",
       "      <td>955</td>\n",
       "      <td>2018-05-28 11:26:27</td>\n",
       "      <td>2018-05-28 14:30:49</td>\n",
       "      <td>11062.0</td>\n",
       "      <td>127.749294</td>\n",
       "      <td>26.141307</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6373</th>\n",
       "      <td>AP622732</td>\n",
       "      <td>2018-06-02</td>\n",
       "      <td>984</td>\n",
       "      <td>985</td>\n",
       "      <td>2018-06-02 11:30:02</td>\n",
       "      <td>2018-06-02 13:56:02</td>\n",
       "      <td>8760.0</td>\n",
       "      <td>127.748537</td>\n",
       "      <td>26.141290</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6374</th>\n",
       "      <td>AP622732</td>\n",
       "      <td>2018-06-05</td>\n",
       "      <td>1011</td>\n",
       "      <td>1013</td>\n",
       "      <td>2018-06-05 14:05:03</td>\n",
       "      <td>2018-06-05 16:58:29</td>\n",
       "      <td>10277.0</td>\n",
       "      <td>127.748348</td>\n",
       "      <td>26.141099</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6375</th>\n",
       "      <td>AP622732</td>\n",
       "      <td>2018-06-19</td>\n",
       "      <td>1141</td>\n",
       "      <td>1142</td>\n",
       "      <td>2018-06-19 11:03:36</td>\n",
       "      <td>2018-06-19 12:14:35</td>\n",
       "      <td>4259.0</td>\n",
       "      <td>127.749403</td>\n",
       "      <td>26.141242</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6376</th>\n",
       "      <td>AP622732</td>\n",
       "      <td>2018-06-26</td>\n",
       "      <td>1202</td>\n",
       "      <td>1203</td>\n",
       "      <td>2018-06-26 10:26:13</td>\n",
       "      <td>2018-06-26 14:04:52</td>\n",
       "      <td>13119.0</td>\n",
       "      <td>127.749361</td>\n",
       "      <td>26.141330</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6377</th>\n",
       "      <td>AP622732</td>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>1258</td>\n",
       "      <td>1259</td>\n",
       "      <td>2018-07-01 11:18:03</td>\n",
       "      <td>2018-07-01 14:46:27</td>\n",
       "      <td>12504.0</td>\n",
       "      <td>127.749516</td>\n",
       "      <td>26.141373</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6378</th>\n",
       "      <td>AP622732</td>\n",
       "      <td>2018-07-21</td>\n",
       "      <td>1373</td>\n",
       "      <td>1374</td>\n",
       "      <td>2018-07-21 15:18:18</td>\n",
       "      <td>2018-07-21 16:49:13</td>\n",
       "      <td>5455.0</td>\n",
       "      <td>127.749085</td>\n",
       "      <td>26.141354</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ap_id        date  trip_prevs  trip_count       ts_prevs_stop  \\\n",
       "6369  AP622732  2018-04-15         602         605 2018-04-15 16:02:14   \n",
       "6370  AP622732  2018-04-16         615         616 2018-04-16 15:34:11   \n",
       "6371  AP622732  2018-05-20         877         878 2018-05-20 14:01:13   \n",
       "6372  AP622732  2018-05-28         954         955 2018-05-28 11:26:27   \n",
       "6373  AP622732  2018-06-02         984         985 2018-06-02 11:30:02   \n",
       "6374  AP622732  2018-06-05        1011        1013 2018-06-05 14:05:03   \n",
       "6375  AP622732  2018-06-19        1141        1142 2018-06-19 11:03:36   \n",
       "6376  AP622732  2018-06-26        1202        1203 2018-06-26 10:26:13   \n",
       "6377  AP622732  2018-07-01        1258        1259 2018-07-01 11:18:03   \n",
       "6378  AP622732  2018-07-21        1373        1374 2018-07-21 15:18:18   \n",
       "\n",
       "               timestamp  stay_time         lon        lat trip_code  \n",
       "6369 2018-04-15 17:39:21     5825.0  127.748504  26.141682         1  \n",
       "6370 2018-04-16 16:59:10     5099.0  127.747982  26.141301         2  \n",
       "6371 2018-05-20 16:42:19     9666.0  127.747158  26.140155         3  \n",
       "6372 2018-05-28 14:30:49    11062.0  127.749294  26.141307         4  \n",
       "6373 2018-06-02 13:56:02     8760.0  127.748537  26.141290         5  \n",
       "6374 2018-06-05 16:58:29    10277.0  127.748348  26.141099         6  \n",
       "6375 2018-06-19 12:14:35     4259.0  127.749403  26.141242         7  \n",
       "6376 2018-06-26 14:04:52    13119.0  127.749361  26.141330         8  \n",
       "6377 2018-07-01 14:46:27    12504.0  127.749516  26.141373         9  \n",
       "6378 2018-07-21 16:49:13     5455.0  127.749085  26.141354        10  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trip_df1 = df_final.query(\"ap_id=='AP622732'\")\n",
    "trip_df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5c8c4a805d92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ap_id=='AP622732' and  tripcount >400\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.query(\"tripcount >4000\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.query(\"ap_id=='AP622732' and  tripcount >400\")#.query(\"tripcount >4000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
